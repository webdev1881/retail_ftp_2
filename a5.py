#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
FTP Analyzer - –≠—Ç–∞–ø 6: –î–µ—Ç–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ—Ç—á–µ—Ç –ø–æ —Å–ø–∏—Å–∞–Ω–∏—è–º
–ê–≤—Ç–æ—Ä: –°–∏—Å—Ç–µ–º–∞ –∞–Ω–∞–ª–∏—Ç–∏–∫–∏ –¥–∞–Ω–Ω—ã—Ö
–í–µ—Ä—Å–∏—è: 6.0
"""

import ftplib
import os
import json
import sys
import csv
import io
from datetime import datetime, timedelta
from pathlib import Path
import pandas as pd

class FTPAnalyzer:
    def __init__(self):
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ FTP-—Å–µ—Ä–≤–µ—Ä–∞
        self.ftp_host = "smkft.space"
        self.ftp_port = 2122
        self.ftp_user = "nielsen"
        self.ftp_pass = "Qazwsx32123"
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –≥–æ—Ä–æ–¥–æ–≤
        self.cities = {
            'khar': '–•–∞—Ä—å–∫–æ–≤',
            'kiev': '–ö–∏–µ–≤', 
            'dnepr': '–î–Ω–µ–ø—Ä',
            'bel': '–ë–µ–ª–∞—è –¶–µ—Ä–∫–æ–≤—å'
        }
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –ª–æ–∫–∞–ª—å–Ω—ã—Ö –ø–∞–ø–æ–∫
        self.base_dir = Path("ftp_data")
        self.cache_dir = self.base_dir / "cache"
        self.reports_dir = self.base_dir / "reports"
        self.structure_file = self.base_dir / "ftp_structure.json"
        
        # –°–æ–∑–¥–∞–µ–º –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –ø–∞–ø–∫–∏
        self.create_directories()
        
    def create_directories(self):
        """–°–æ–∑–¥–∞–µ—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –ø–∞–ø–∫–∏ –¥–ª—è —Ä–∞–±–æ—Ç—ã –ø—Ä–æ–≥—Ä–∞–º–º—ã"""
        try:
            self.base_dir.mkdir(exist_ok=True)
            self.cache_dir.mkdir(exist_ok=True)
            self.reports_dir.mkdir(exist_ok=True)
            print(f"‚úì –°–æ–∑–¥–∞–Ω–∞ —Ä–∞–±–æ—á–∞—è –ø–∞–ø–∫–∞: {self.base_dir.absolute()}")
            print(f"‚úì –°–æ–∑–¥–∞–Ω–∞ –ø–∞–ø–∫–∞ –∫–µ—à–∞: {self.cache_dir.absolute()}")
            print(f"‚úì –°–æ–∑–¥–∞–Ω–∞ –ø–∞–ø–∫–∞ –æ—Ç—á–µ—Ç–æ–≤: {self.reports_dir.absolute()}")
        except Exception as e:
            print(f"‚úó –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –ø–∞–ø–æ–∫: {e}")
            sys.exit(1)
            
    def clear_cache(self):
        """–û—á–∏—â–∞–µ—Ç –∫–µ—à"""
        try:
            import shutil
            if self.cache_dir.exists():
                shutil.rmtree(self.cache_dir)
                self.cache_dir.mkdir()
                print("‚úì –ö–µ—à –æ—á–∏—â–µ–Ω")
                return True
        except Exception as e:
            print(f"‚úó –û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ –∫–µ—à–∞: {e}")
            return False
            
    def ask_clear_cache(self):
        """–°–ø—Ä–∞—à–∏–≤–∞–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –æ–± –æ—á–∏—Å—Ç–∫–µ –∫–µ—à–∞"""
        while True:
            choice = input("\nüóëÔ∏è  –û—á–∏—Å—Ç–∏—Ç—å –∫–µ—à –ø–µ—Ä–µ–¥ –∑–∞–≥—Ä—É–∑–∫–æ–π? (y/n): ").lower().strip()
            if choice in ['y', 'yes', '–¥', '–¥–∞']:
                return self.clear_cache()
            elif choice in ['n', 'no', '–Ω', '–Ω–µ—Ç']:
                print("‚ÑπÔ∏è  –ö–µ—à —Å–æ—Ö—Ä–∞–Ω–µ–Ω")
                return True
            else:
                print("‚ùå –í–≤–µ–¥–∏—Ç–µ 'y' –¥–ª—è –¥–∞ –∏–ª–∏ 'n' –¥–ª—è –Ω–µ—Ç")
                
    def connect_ftp(self):
        """–ü–æ–¥–∫–ª—é—á–∞–µ—Ç—Å—è –∫ FTP-—Å–µ—Ä–≤–µ—Ä—É"""
        try:
            print(f"üîÑ –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è –∫ FTP-—Å–µ—Ä–≤–µ—Ä—É {self.ftp_host}:{self.ftp_port}...")
            ftp = ftplib.FTP()
            ftp.connect(self.ftp_host, self.ftp_port)
            ftp.login(self.ftp_user, self.ftp_pass)
            print("‚úì –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ FTP —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ")
            return ftp
        except ftplib.error_perm as e:
            print(f"‚úó –û—à–∏–±–∫–∞ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏ FTP: {e}")
            return None
        except Exception as e:
            print(f"‚úó –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ FTP: {e}")
            return None
            
    def download_file(self, ftp, remote_path, local_path):
        """–°–∫–∞—á–∏–≤–∞–µ—Ç —Ñ–∞–π–ª —Å FTP —Å–µ—Ä–≤–µ—Ä–∞"""
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —Ñ–∞–π–ª –≤ –∫–µ—à–µ
            if local_path.exists():
                print(f"üìÑ –§–∞–π–ª –Ω–∞–π–¥–µ–Ω –≤ –∫–µ—à–µ: {local_path.name}")
                return True
                
            print(f"‚¨áÔ∏è  –°–∫–∞—á–∏–≤–∞–µ–º: {remote_path}")
            local_path.parent.mkdir(parents=True, exist_ok=True)
            
            with open(local_path, 'wb') as f:
                ftp.retrbinary(f'RETR {remote_path}', f.write)
            
            print(f"‚úì –°–∫–∞—á–∞–Ω: {local_path.name}")
            return True
            
        except ftplib.error_perm as e:
            if "550" in str(e):  # –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω
                print(f"‚ö†Ô∏è  –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {remote_path}")
            else:
                print(f"‚úó –û—à–∏–±–∫–∞ FTP –ø—Ä–∏ —Å–∫–∞—á–∏–≤–∞–Ω–∏–∏ {remote_path}: {e}")
            return False
        except Exception as e:
            print(f"‚úó –û—à–∏–±–∫–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è {remote_path}: {e}")
            return False
            
    def read_csv_with_pipe(self, file_path):
        """–ß–∏—Ç–∞–µ—Ç CSV —Ñ–∞–π–ª —Å —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–µ–º |"""
        try:
            df = pd.read_csv(file_path, sep='|', encoding='utf-8')
            
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —á–∏—Å–ª–æ–≤—ã–µ –ø–æ–ª—è –≤ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ —Ç–∏–ø—ã
            file_name = file_path.name.lower()
            
            if 'lossproduct' in file_name:
                # –î–ª—è —Ñ–∞–π–ª–æ–≤ lossproduct –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º qty –∏ total_price –≤ —á–∏—Å–ª–∞
                if 'qty' in df.columns:
                    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —á–∏—Å–ª–∞ —Å –∑–∞–ø—è—Ç–æ–π –∫–∞–∫ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–µ–º –¥–µ—Å—è—Ç–∏—á–Ω—ã—Ö
                    df['qty'] = df['qty'].astype(str).str.replace(',', '.', regex=False)
                    df['qty'] = pd.to_numeric(df['qty'], errors='coerce').fillna(0)
                if 'total_price' in df.columns:
                    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —á–∏—Å–ª–∞ —Å –∑–∞–ø—è—Ç–æ–π –∫–∞–∫ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–µ–º –¥–µ—Å—è—Ç–∏—á–Ω—ã—Ö
                    df['total_price'] = df['total_price'].astype(str).str.replace(',', '.', regex=False)
                    df['total_price'] = pd.to_numeric(df['total_price'], errors='coerce').fillna(0.0)
            
            # –£–±–∏—Ä–∞–µ–º –ø—Ä–æ–±–µ–ª—ã –∏–∑ —Å—Ç—Ä–æ–∫–æ–≤—ã—Ö –ø–æ–ª–µ–π
            for col in df.columns:
                if df[col].dtype == 'object':
                    df[col] = df[col].astype(str).str.strip()
            
            print(f"‚úì –ü—Ä–æ—á–∏—Ç–∞–Ω CSV: {file_path.name} ({len(df)} —Å—Ç—Ä–æ–∫)")
            return df
        except Exception as e:
            print(f"‚úó –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è CSV {file_path}: {e}")
            return None
            
    def generate_date_range(self, start_date, end_date):
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Å–ø–∏—Å–æ–∫ –¥–∞—Ç –≤ —É–∫–∞–∑–∞–Ω–Ω–æ–º –¥–∏–∞–ø–∞–∑–æ–Ω–µ"""
        dates = []
        current_date = datetime.strptime(start_date, '%Y-%m-%d')
        end_date_obj = datetime.strptime(end_date, '%Y-%m-%d')
        
        while current_date <= end_date_obj:
            dates.append(current_date.strftime('%Y-%m-%d'))
            current_date += timedelta(days=1)
            
        return dates
        
    def download_losstype_file(self, ftp):
        """–°–∫–∞—á–∏–≤–∞–µ—Ç —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫ —Ç–∏–ø–æ–≤ —Å–ø–∏—Å–∞–Ω–∏–π"""
        print("\nüìã –ó–ê–ì–†–£–ó–ö–ê –°–ü–†–ê–í–û–ß–ù–ò–ö–ê –¢–ò–ü–û–í –°–ü–ò–°–ê–ù–ò–ô")
        print("-" * 50)
        
        remote_path = "/www/losstype.csv"
        local_path = self.cache_dir / "losstype.csv"
        
        if self.download_file(ftp, remote_path, local_path):
            df = self.read_csv_with_pipe(local_path)
            if df is not None:
                print(f"  üìä –¢–∏–ø–æ–≤ —Å–ø–∏—Å–∞–Ω–∏–π: {len(df)}")
                return df
        
        return None
        
    def download_shop_files(self, ftp):
        """–°–∫–∞—á–∏–≤–∞–µ—Ç —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫–∏ –º–∞–≥–∞–∑–∏–Ω–æ–≤"""
        print("\nüìã –ó–ê–ì–†–£–ó–ö–ê –°–ü–†–ê–í–û–ß–ù–ò–ö–û–í –ú–ê–ì–ê–ó–ò–ù–û–í")
        print("-" * 40)
        
        shops_data = {}
        
        for city_code, city_name in self.cities.items():
            remote_path = f"/www/shop_{city_code}.csv"
            local_path = self.cache_dir / f"shop_{city_code}.csv"
            
            if self.download_file(ftp, remote_path, local_path):
                df = self.read_csv_with_pipe(local_path)
                if df is not None:
                    shops_data[city_code] = df
                    print(f"  üìä {city_name}: {len(df)} –º–∞–≥–∞–∑–∏–Ω–æ–≤")
                    
        return shops_data
        
    def download_loss_data(self, ftp, start_date, end_date):
        """–°–∫–∞—á–∏–≤–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –æ —Å–ø–∏—Å–∞–Ω–∏—è—Ö –∏ –ø—Ä–æ–¥—É–∫—Ç–∞—Ö —Å–ø–∏—Å–∞–Ω–∏–π –∑–∞ —É–∫–∞–∑–∞–Ω–Ω—ã–π –ø–µ—Ä–∏–æ–¥"""
        print(f"\nüìâ –ó–ê–ì–†–£–ó–ö–ê –î–ê–ù–ù–´–• –û –°–ü–ò–°–ê–ù–ò–Ø–• ({start_date} - {end_date})")
        print("-" * 70)
        
        dates = self.generate_date_range(start_date, end_date)
        loss_data = {}
        lossproduct_data = {}
        
        for city_code, city_name in self.cities.items():
            print(f"\nüèôÔ∏è  {city_name} ({city_code}):")
            loss_data[city_code] = []
            lossproduct_data[city_code] = []
            
            for date in dates:
                # –°–∫–∞—á–∏–≤–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã —Å–ø–∏—Å–∞–Ω–∏–π
                loss_remote = f"/www/loss/loss_{city_code}_{date}.csv"
                loss_local = self.cache_dir / f"loss_{city_code}_{date}.csv"
                
                # –°–∫–∞—á–∏–≤–∞–µ–º –ø—Ä–æ–¥—É–∫—Ç—ã —Å–ø–∏—Å–∞–Ω–∏–π
                lossproduct_remote = f"/www/lossproduct/lossproduct_{city_code}_{date}.csv"
                lossproduct_local = self.cache_dir / f"lossproduct_{city_code}_{date}.csv"
                
                loss_loaded = False
                lossproduct_loaded = False
                
                # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã —Å–ø–∏—Å–∞–Ω–∏–π
                if self.download_file(ftp, loss_remote, loss_local):
                    df = self.read_csv_with_pipe(loss_local)
                    if df is not None:
                        df['date'] = date
                        loss_data[city_code].append(df)
                        loss_loaded = True
                        
                # –ó–∞–≥—Ä—É–∂–∞–µ–º –ø—Ä–æ–¥—É–∫—Ç—ã —Å–ø–∏—Å–∞–Ω–∏–π
                if self.download_file(ftp, lossproduct_remote, lossproduct_local):
                    df = self.read_csv_with_pipe(lossproduct_local)
                    if df is not None:
                        df['date'] = date
                        lossproduct_data[city_code].append(df)
                        lossproduct_loaded = True
                        
                if loss_loaded and lossproduct_loaded:
                    loss_df = loss_data[city_code][-1]
                    lossproduct_df = lossproduct_data[city_code][-1]
                    total_qty = float(lossproduct_df['qty'].sum()) if 'qty' in lossproduct_df.columns else 0.0
                    total_price = float(lossproduct_df['total_price'].sum()) if 'total_price' in lossproduct_df.columns else 0.0
                    print(f"    üìÖ {date}: {len(loss_df)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤, {len(lossproduct_df)} –ø–æ–∑–∏—Ü–∏–π, —Ç–æ–≤–∞—Ä–æ–≤: {total_qty:.1f}, —Å—É–º–º–∞: {total_price:.2f}")
                elif loss_loaded:
                    loss_df = loss_data[city_code][-1]
                    print(f"    üìÖ {date}: {len(loss_df)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ —Å–ø–∏—Å–∞–Ω–∏–π")
                    
        return loss_data, lossproduct_data
        
    def consolidate_detailed_loss_data(self, shops_data, losstype_data, loss_data, lossproduct_data):
        """–ö–æ–Ω—Å–æ–ª–∏–¥–∏—Ä—É–µ—Ç –¥–µ—Ç–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –ø–æ —Å–ø–∏—Å–∞–Ω–∏—è–º –∏ —Å–æ–∑–¥–∞–µ—Ç –æ—Ç—á–µ—Ç"""
        print("\nüìä –ö–û–ù–°–û–õ–ò–î–ê–¶–ò–Ø –î–ï–¢–ê–õ–ò–ó–ò–†–û–í–ê–ù–ù–´–• –î–ê–ù–ù–´–• –ü–û –°–ü–ò–°–ê–ù–ò–Ø–ú")
        print("-" * 60)
        
        if losstype_data is None:
            print("‚ùå –û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫ —Ç–∏–ø–æ–≤ —Å–ø–∏—Å–∞–Ω–∏–π")
            return []
        
        report_data = []
        
        for city_code, city_name in self.cities.items():
            print(f"\nüèôÔ∏è  –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º {city_name}...")
            
            if city_code not in shops_data:
                print(f"  ‚ö†Ô∏è  –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –æ –º–∞–≥–∞–∑–∏–Ω–∞—Ö –¥–ª—è {city_name}")
                continue
                
            shops_df = shops_data[city_code]
            
            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –≤—Å–µ—Ö –º–∞–≥–∞–∑–∏–Ω–æ–≤ –∏ —Ç–∏–ø–æ–≤ —Å–ø–∏—Å–∞–Ω–∏–π
            for _, shop in shops_df.iterrows():
                for _, losstype in losstype_data.iterrows():
                    report_data.append({
                        '–ì–æ—Ä–æ–¥': city_name,
                        'ID_–º–∞–≥–∞–∑–∏–Ω–∞': shop['id'],
                        '–ù–∞–∑–≤–∞–Ω–∏–µ_–º–∞–≥–∞–∑–∏–Ω–∞': shop['name'],
                        'ID_—Ç–∏–ø–∞_—Å–ø–∏—Å–∞–Ω–∏—è': losstype['id'],
                        '–¢–∏–ø_—Å–ø–∏—Å–∞–Ω–∏—è': losstype['name'],
                        '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ_–¥–æ–∫—É–º–µ–Ω—Ç–æ–≤': 0,
                        '–°—É–º–º–∞_—Å–ø–∏—Å–∞–Ω–∏–π': 0.0,
                        '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ_—Ç–æ–≤–∞—Ä–æ–≤': 0.0
                    })
            
            if city_code not in loss_data or not loss_data[city_code]:
                print(f"  ‚ö†Ô∏è  –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –æ —Å–ø–∏—Å–∞–Ω–∏—è—Ö –¥–ª—è {city_name}")
                continue
                
            # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã —Å–ø–∏—Å–∞–Ω–∏–π –ø–æ –≥–æ—Ä–æ–¥—É
            all_losses = pd.concat(loss_data[city_code], ignore_index=True)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–≤—è–∑—å –º–µ–∂–¥—É —Å–ø–∏—Å–∞–Ω–∏—è–º–∏ –∏ –º–∞–≥–∞–∑–∏–Ω–∞–º–∏
            valid_shop_ids = set(shops_df['id'].astype(str))
            valid_losses = all_losses[all_losses['shop_id'].astype(str).isin(valid_shop_ids)]
            
            if len(valid_losses) < len(all_losses):
                invalid_count = len(all_losses) - len(valid_losses)
                print(f"  ‚ö†Ô∏è  –ò—Å–∫–ª—é—á–µ–Ω–æ {invalid_count} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ —Å –Ω–µ–≤–µ—Ä–Ω—ã–º–∏ shop_id")
            
            if len(valid_losses) == 0:
                print(f"  ‚ö†Ô∏è  –ù–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –æ —Å–ø–∏—Å–∞–Ω–∏—è—Ö –¥–ª—è {city_name}")
                continue
            
            # –°—á–∏—Ç–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –ø–æ –º–∞–≥–∞–∑–∏–Ω–∞–º –∏ —Ç–∏–ø–∞–º
            loss_counts = valid_losses.groupby(['shop_id', 'type_id']).size().reset_index(name='document_count')
            
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –ø—Ä–æ–¥—É–∫—Ç—ã —Å–ø–∏—Å–∞–Ω–∏–π –µ—Å–ª–∏ –µ—Å—Ç—å –¥–∞–Ω–Ω—ã–µ
            loss_with_products = None
            if city_code in lossproduct_data and lossproduct_data[city_code]:
                print(f"  üõí –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –ø—Ä–æ–¥—É–∫—Ç—ã —Å–ø–∏—Å–∞–Ω–∏–π...")
                
                # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ –ø—Ä–æ–¥—É–∫—Ç—ã —Å–ø–∏—Å–∞–Ω–∏–π –ø–æ –≥–æ—Ä–æ–¥—É
                all_lossproducts = pd.concat(lossproduct_data[city_code], ignore_index=True)
                
                # –°–≤—è–∑—ã–≤–∞–µ–º –ø—Ä–æ–¥—É–∫—Ç—ã —Å –¥–æ–∫—É–º–µ–Ω—Ç–∞–º–∏ —Å–ø–∏—Å–∞–Ω–∏–π
                lossproducts_with_docs = all_lossproducts.merge(
                    valid_losses[['id', 'shop_id', 'type_id']], 
                    left_on='document_id', 
                    right_on='id', 
                    how='inner'
                )
                
                if not lossproducts_with_docs.empty:
                    # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ –º–∞–≥–∞–∑–∏–Ω–∞–º –∏ —Ç–∏–ø–∞–º —Å–ø–∏—Å–∞–Ω–∏–π
                    loss_with_products = lossproducts_with_docs.groupby(['shop_id', 'type_id']).agg({
                        'total_price': 'sum',
                        'qty': 'sum'
                    }).reset_index()
                    
                    # –£–±–µ–∂–¥–∞–µ–º—Å—è —á—Ç–æ –¥–∞–Ω–Ω—ã–µ –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ
                    loss_with_products['total_price'] = pd.to_numeric(loss_with_products['total_price'], errors='coerce').fillna(0.0)
                    loss_with_products['qty'] = pd.to_numeric(loss_with_products['qty'], errors='coerce').fillna(0.0)
                    
                    print(f"    ‚úì –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –ø—Ä–æ–¥—É–∫—Ç–æ–≤ —Å–ø–∏—Å–∞–Ω–∏–π: {len(all_lossproducts)}")
                    print(f"    ‚úì –°–≤—è–∑–∞–Ω–æ —Å –¥–æ–∫—É–º–µ–Ω—Ç–∞–º–∏: {len(lossproducts_with_docs)}")
                else:
                    print(f"    ‚ö†Ô∏è  –ù–µ —É–¥–∞–ª–æ—Å—å —Å–≤—è–∑–∞—Ç—å –ø—Ä–æ–¥—É–∫—Ç—ã —Å –¥–æ–∫—É–º–µ–Ω—Ç–∞–º–∏ —Å–ø–∏—Å–∞–Ω–∏–π")
            else:
                print(f"  ‚ö†Ô∏è  –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –æ –ø—Ä–æ–¥—É–∫—Ç–∞—Ö —Å–ø–∏—Å–∞–Ω–∏–π –¥–ª—è {city_name}")
            
            # –û–±–Ω–æ–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ –æ—Ç—á–µ—Ç–∞
            for i, row in enumerate(report_data):
                if row['–ì–æ—Ä–æ–¥'] == city_name:
                    shop_id = str(row['ID_–º–∞–≥–∞–∑–∏–Ω–∞'])
                    type_id = str(row['ID_—Ç–∏–ø–∞_—Å–ø–∏—Å–∞–Ω–∏—è'])
                    
                    # –û–±–Ω–æ–≤–ª—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
                    doc_match = loss_counts[
                        (loss_counts['shop_id'].astype(str) == shop_id) & 
                        (loss_counts['type_id'].astype(str) == type_id)
                    ]
                    if not doc_match.empty:
                        report_data[i]['–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ_–¥–æ–∫—É–º–µ–Ω—Ç–æ–≤'] = int(doc_match.iloc[0]['document_count'])
                    
                    # –û–±–Ω–æ–≤–ª—è–µ–º —Å—É–º–º—É –∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–≤–∞—Ä–æ–≤
                    if loss_with_products is not None:
                        product_match = loss_with_products[
                            (loss_with_products['shop_id'].astype(str) == shop_id) & 
                            (loss_with_products['type_id'].astype(str) == type_id)
                        ]
                        if not product_match.empty:
                            report_data[i]['–°—É–º–º–∞_—Å–ø–∏—Å–∞–Ω–∏–π'] = float(product_match.iloc[0]['total_price'])
                            report_data[i]['–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ_—Ç–æ–≤–∞—Ä–æ–≤'] = float(product_match.iloc[0]['qty'])
            
            total_documents = len(all_losses)
            valid_documents = len(valid_losses)
            total_amount = 0.0
            total_quantity = 0.0
            
            if loss_with_products is not None:
                total_amount = float(loss_with_products['total_price'].sum())
                total_quantity = float(loss_with_products['qty'].sum())
            
            print(f"  ‚úì –í—Å–µ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {total_documents}")
            print(f"  ‚úì –ö–æ—Ä—Ä–µ–∫—Ç–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {valid_documents}")
            print(f"  ‚úì –û–±—â–∞—è —Å—É–º–º–∞ —Å–ø–∏—Å–∞–Ω–∏–π: {total_amount:.2f}")
            print(f"  ‚úì –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–≤–∞—Ä–æ–≤: {total_quantity:.1f}")
            
        return report_data
        
    def save_detailed_loss_excel_report(self, report_data, start_date, end_date):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –¥–µ—Ç–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ—Ç—á–µ—Ç –ø–æ —Å–ø–∏—Å–∞–Ω–∏—è–º –≤ Excel"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        # –°–æ–∑–¥–∞–µ–º DataFrame
        df = pd.DataFrame(report_data)
        
        # –§–∏–ª—å—Ç—Ä—É–µ–º –∑–∞–ø–∏—Å–∏ —Å –Ω—É–ª–µ–≤—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏ –¥–ª—è –∫—Ä–∞—Ç–∫–æ—Å—Ç–∏
        df_filtered = df[
            (df['–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ_–¥–æ–∫—É–º–µ–Ω—Ç–æ–≤'] > 0) | 
            (df['–°—É–º–º–∞_—Å–ø–∏—Å–∞–Ω–∏–π'] > 0) | 
            (df['–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ_—Ç–æ–≤–∞—Ä–æ–≤'] > 0)
        ].copy()
        
        # –ï—Å–ª–∏ –Ω–µ—Ç –∞–∫—Ç–∏–≤–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π, –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –≤—Å–µ
        if df_filtered.empty:
            df_filtered = df.copy()
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –≥–æ—Ä–æ–¥—É, –º–∞–≥–∞–∑–∏–Ω—É –∏ —Å—É–º–º–µ —Å–ø–∏—Å–∞–Ω–∏–π
        df_filtered = df_filtered.sort_values(['–ì–æ—Ä–æ–¥', '–ù–∞–∑–≤–∞–Ω–∏–µ_–º–∞–≥–∞–∑–∏–Ω–∞', '–°—É–º–º–∞_—Å–ø–∏—Å–∞–Ω–∏–π'], ascending=[True, True, False])
        
        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —á–∏—Å–ª–æ–≤—ã–µ –ø–æ–ª—è
        df_filtered['–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ_–¥–æ–∫—É–º–µ–Ω—Ç–æ–≤'] = df_filtered['–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ_–¥–æ–∫—É–º–µ–Ω—Ç–æ–≤'].astype(int)
        df_filtered['–°—É–º–º–∞_—Å–ø–∏—Å–∞–Ω–∏–π'] = pd.to_numeric(df_filtered['–°—É–º–º–∞_—Å–ø–∏—Å–∞–Ω–∏–π'], errors='coerce').fillna(0.0).round(2)
        df_filtered['–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ_—Ç–æ–≤–∞—Ä–æ–≤'] = pd.to_numeric(df_filtered['–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ_—Ç–æ–≤–∞—Ä–æ–≤'], errors='coerce').fillna(0.0).round(1)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ Excel
        excel_file = self.reports_dir / f"detailed_loss_report_{start_date}_{end_date}_{timestamp}.xlsx"
        
        with pd.ExcelWriter(excel_file, engine='openpyxl') as writer:
            df_filtered.to_excel(writer, sheet_name='–î–µ—Ç–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ—Ç—á–µ—Ç', index=False)
            
            # –ü–æ–ª—É—á–∞–µ–º –æ–±—ä–µ–∫—Ç —Ä–∞–±–æ—á–µ–≥–æ –ª–∏—Å—Ç–∞ –¥–ª—è —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
            worksheet = writer.sheets['–î–µ—Ç–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ—Ç—á–µ—Ç']
            
            # –ê–≤—Ç–æ—à–∏—Ä–∏–Ω–∞ –∫–æ–ª–æ–Ω–æ–∫
            for column in worksheet.columns:
                max_length = 0
                column_letter = column[0].column_letter
                for cell in column:
                    try:
                        if len(str(cell.value)) > max_length:
                            max_length = len(str(cell.value))
                    except:
                        pass
                adjusted_width = min(max_length + 2, 40)
                worksheet.column_dimensions[column_letter].width = adjusted_width
        
        print(f"\nüìÑ –î–ï–¢–ê–õ–ò–ó–ò–†–û–í–ê–ù–ù–´–ô –û–¢–ß–ï–¢ –ü–û –°–ü–ò–°–ê–ù–ò–Ø–ú –°–û–•–†–ê–ù–ï–ù:")
        print(f"  Excel: {excel_file.absolute()}")
        print(f"  üìä –ó–∞–ø–∏—Å–µ–π –≤ –æ—Ç—á–µ—Ç–µ: {len(df_filtered)} (–∏–∑ {len(df)} –≤—Å–µ–≥–æ)")
        
        return df_filtered
        
    def print_detailed_loss_report_summary(self, df):
        """–í—ã–≤–æ–¥–∏—Ç –∫—Ä–∞—Ç–∫—É—é —Å–≤–æ–¥–∫—É –¥–µ—Ç–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞ –ø–æ —Å–ø–∏—Å–∞–Ω–∏—è–º"""
        print(f"\nüìà –°–í–û–î–ö–ê –î–ï–¢–ê–õ–ò–ó–ò–†–û–í–ê–ù–ù–û–ì–û –û–¢–ß–ï–¢–ê –ü–û –°–ü–ò–°–ê–ù–ò–Ø–ú:")
        print("-" * 60)
        
        total_documents = int(df['–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ_–¥–æ–∫—É–º–µ–Ω—Ç–æ–≤'].sum())
        total_amount = float(df['–°—É–º–º–∞_—Å–ø–∏—Å–∞–Ω–∏–π'].sum())
        total_quantity = float(df['–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ_—Ç–æ–≤–∞—Ä–æ–≤'].sum())
        active_records = len(df[df['–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ_–¥–æ–∫—É–º–µ–Ω—Ç–æ–≤'] > 0])
        
        print(f"üìä –ê–∫—Ç–∏–≤–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π –≤ –æ—Ç—á–µ—Ç–µ: {active_records}")
        print(f"üìâ –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ —Å–ø–∏—Å–∞–Ω–∏–π: {total_documents:,}")
        print(f"üí∞ –û–±—â–∞—è —Å—É–º–º–∞ —Å–ø–∏—Å–∞–Ω–∏–π: {total_amount:,.2f}")
        print(f"üì¶ –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–≤–∞—Ä–æ–≤: {total_quantity:,.1f}")
        
        if total_documents > 0:
            avg_amount_per_doc = total_amount / total_documents
            avg_quantity_per_doc = total_quantity / total_documents
            print(f"üìà –°—Ä–µ–¥–Ω—è—è —Å—É–º–º–∞ –Ω–∞ –¥–æ–∫—É–º–µ–Ω—Ç: {avg_amount_per_doc:.2f}")
            print(f"üìà –°—Ä–µ–¥–Ω–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–≤–∞—Ä–æ–≤ –Ω–∞ –¥–æ–∫—É–º–µ–Ω—Ç: {avg_quantity_per_doc:.1f}")
        
        # –¢–û–ü –º–∞–≥–∞–∑–∏–Ω–æ–≤ –ø–æ —Å—É–º–º–µ —Å–ø–∏—Å–∞–Ω–∏–π
        print(f"\nüèÜ –¢–û–ü-5 –ú–ê–ì–ê–ó–ò–ù–û–í –ü–û –°–£–ú–ú–ï –°–ü–ò–°–ê–ù–ò–ô:")
        shop_summary = df.groupby(['–ì–æ—Ä–æ–¥', '–ù–∞–∑–≤–∞–Ω–∏–µ_–º–∞–≥–∞–∑–∏–Ω–∞']).agg({
            '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ_–¥–æ–∫—É–º–µ–Ω—Ç–æ–≤': 'sum',
            '–°—É–º–º–∞_—Å–ø–∏—Å–∞–Ω–∏–π': 'sum',
            '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ_—Ç–æ–≤–∞—Ä–æ–≤': 'sum'
        }).reset_index().sort_values('–°—É–º–º–∞_—Å–ø–∏—Å–∞–Ω–∏–π', ascending=False)
        
        for i, (_, row) in enumerate(shop_summary.head(5).iterrows(), 1):
            if row['–°—É–º–º–∞_—Å–ø–∏—Å–∞–Ω–∏–π'] > 0:
                print(f"  {i}. {row['–ù–∞–∑–≤–∞–Ω–∏–µ_–º–∞–≥–∞–∑–∏–Ω–∞']} ({row['–ì–æ—Ä–æ–¥']}) - {float(row['–°—É–º–º–∞_—Å–ø–∏—Å–∞–Ω–∏–π']):,.2f}, {int(row['–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ_–¥–æ–∫—É–º–µ–Ω—Ç–æ–≤'])} –¥–æ–∫.")
        
        # –¢–û–ü —Ç–∏–ø–æ–≤ —Å–ø–∏—Å–∞–Ω–∏–π
        print(f"\nüèÜ –¢–û–ü-5 –¢–ò–ü–û–í –°–ü–ò–°–ê–ù–ò–ô –ü–û –°–£–ú–ú–ï:")
        type_summary = df.groupby('–¢–∏–ø_—Å–ø–∏—Å–∞–Ω–∏—è').agg({
            '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ_–¥–æ–∫—É–º–µ–Ω—Ç–æ–≤': 'sum',
            '–°—É–º–º–∞_—Å–ø–∏—Å–∞–Ω–∏–π': 'sum',
            '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ_—Ç–æ–≤–∞—Ä–æ–≤': 'sum'
        }).reset_index().sort_values('–°—É–º–º–∞_—Å–ø–∏—Å–∞–Ω–∏–π', ascending=False)
        
        for i, (_, row) in enumerate(type_summary.head(5).iterrows(), 1):
            if row['–°—É–º–º–∞_—Å–ø–∏—Å–∞–Ω–∏–π'] > 0:
                print(f"  {i}. {row['–¢–∏–ø_—Å–ø–∏—Å–∞–Ω–∏—è']} - {float(row['–°—É–º–º–∞_—Å–ø–∏—Å–∞–Ω–∏–π']):,.2f}, {int(row['–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ_–¥–æ–∫—É–º–µ–Ω—Ç–æ–≤'])} –¥–æ–∫.")
        
        # –ü–æ –≥–æ—Ä–æ–¥–∞–º
        print(f"\nüèôÔ∏è  –ü–û –ì–û–†–û–î–ê–ú:")
        city_summary = df.groupby('–ì–æ—Ä–æ–¥').agg({
            '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ_–¥–æ–∫—É–º–µ–Ω—Ç–æ–≤': 'sum',
            '–°—É–º–º–∞_—Å–ø–∏—Å–∞–Ω–∏–π': 'sum',
            '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ_—Ç–æ–≤–∞—Ä–æ–≤': 'sum'
        }).round(2)
        
        for city in city_summary.index:
            docs_count = int(city_summary.loc[city, '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ_–¥–æ–∫—É–º–µ–Ω—Ç–æ–≤'])
            amount = float(city_summary.loc[city, '–°—É–º–º–∞_—Å–ø–∏—Å–∞–Ω–∏–π'])
            quantity = float(city_summary.loc[city, '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ_—Ç–æ–≤–∞—Ä–æ–≤'])
            print(f"  {city}: {docs_count} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤, —Å—É–º–º–∞: {amount:,.2f}, —Ç–æ–≤–∞—Ä–æ–≤: {quantity:,.1f}")
                
    def run_detailed_loss_report_generation(self):
        """–ó–∞–ø—É—Å–∫–∞–µ—Ç –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –¥–µ—Ç–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞ –ø–æ —Å–ø–∏—Å–∞–Ω–∏—è–º"""
        print("=" * 80)
        print("üöÄ –ì–ï–ù–ï–†–ê–¶–ò–Ø –î–ï–¢–ê–õ–ò–ó–ò–†–û–í–ê–ù–ù–û–ì–û –û–¢–ß–ï–¢–ê –ü–û –°–ü–ò–°–ê–ù–ò–Ø–ú")
        print("=" * 80)
        
        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –æ—Ç—á–µ—Ç–∞
        start_date = "2025-05-01"
        end_date = "2025-06-05"
        
        print(f"üìÖ –ü–µ—Ä–∏–æ–¥: {start_date} - {end_date}")
        print(f"üèôÔ∏è  –ì–æ—Ä–æ–¥–∞: {', '.join(self.cities.values())}")
        print(f"üìä –ü–æ–∫–∞–∑–∞—Ç–µ–ª–∏: –ì–æ—Ä–æ–¥ - –ú–∞–≥–∞–∑–∏–Ω - –¢–∏–ø —Å–ø–∏—Å–∞–Ω–∏—è - –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ - –°—É–º–º–∞ - –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–≤–∞—Ä–æ–≤")
        
        # –°–ø—Ä–∞—à–∏–≤–∞–µ–º –æ–± –æ—á–∏—Å—Ç–∫–µ –∫–µ—à–∞
        if not self.ask_clear_cache():
            return False
            
        # –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è –∫ FTP
        ftp = self.connect_ftp()
        if not ftp:
            print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ FTP-—Å–µ—Ä–≤–µ—Ä—É")
            return False
            
        try:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫ —Ç–∏–ø–æ–≤ —Å–ø–∏—Å–∞–Ω–∏–π
            losstype_data = self.download_losstype_file(ftp)
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫–∏ –º–∞–≥–∞–∑–∏–Ω–æ–≤
            shops_data = self.download_shop_files(ftp)
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –æ —Å–ø–∏—Å–∞–Ω–∏—è—Ö –∏ –ø—Ä–æ–¥—É–∫—Ç–∞—Ö
            loss_data, lossproduct_data = self.download_loss_data(ftp, start_date, end_date)
            
            # –ó–∞–∫—Ä—ã–≤–∞–µ–º —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ
            ftp.quit()
            print("\n‚úì –°–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —Å FTP –∑–∞–∫—Ä—ã—Ç–æ")
            
            # –ö–æ–Ω—Å–æ–ª–∏–¥–∏—Ä—É–µ–º –¥–µ—Ç–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –ø–æ —Å–ø–∏—Å–∞–Ω–∏—è–º
            report_data = self.consolidate_detailed_loss_data(shops_data, losstype_data, loss_data, lossproduct_data)
            
            if not report_data:
                print("‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –æ—Ç—á–µ—Ç–∞")
                return False
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç—á–µ—Ç
            df = self.save_detailed_loss_excel_report(report_data, start_date, end_date)
            
            # –í—ã–≤–æ–¥–∏–º —Å–≤–æ–¥–∫—É
            self.print_detailed_loss_report_summary(df)
            
            print(f"\n‚úÖ –î–ï–¢–ê–õ–ò–ó–ò–†–û–í–ê–ù–ù–´–ô –û–¢–ß–ï–¢ –ü–û –°–ü–ò–°–ê–ù–ò–Ø–ú –£–°–ü–ï–®–ù–û –°–ì–ï–ù–ï–†–ò–†–û–í–ê–ù!")
            print(f"üìÅ –ü–∞–ø–∫–∞ –æ—Ç—á–µ—Ç–æ–≤: {self.reports_dir.absolute()}")
            return True
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç—á–µ—Ç–∞: {e}")
            try:
                ftp.quit()
            except:
                pass
            return False

def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø—Ä–æ–≥—Ä–∞–º–º—ã"""
    print("FTP Analyzer v6.0 - –î–µ—Ç–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä —Å–ø–∏—Å–∞–Ω–∏–π")
    print("–ê–≤—Ç–æ—Ä: –°–∏—Å—Ç–µ–º–∞ –∞–Ω–∞–ª–∏—Ç–∏–∫–∏ –¥–∞–Ω–Ω—ã—Ö\n")
    
    try:
        analyzer = FTPAnalyzer()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –±–∏–±–ª–∏–æ—Ç–µ–∫
        try:
            import pandas as pd
            import openpyxl
        except ImportError as e:
            print("‚ùå –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏!")
            print("–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –∏—Ö –∫–æ–º–∞–Ω–¥–∞–º–∏:")
            print("pip install pandas openpyxl")
            return
        
        # –°—Ä–∞–∑—É –∑–∞–ø—É—Å–∫–∞–µ–º –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –¥–µ—Ç–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞ –ø–æ —Å–ø–∏—Å–∞–Ω–∏—è–º
        analyzer.run_detailed_loss_report_generation()
                
    except KeyboardInterrupt:
        print("\n\n‚èπÔ∏è  –ü—Ä–æ–≥—Ä–∞–º–º–∞ –ø—Ä–µ—Ä–≤–∞–Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
    except Exception as e:
        print(f"\n‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")

if __name__ == "__main__":
    main()